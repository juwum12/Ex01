{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1cbf8e",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3f34616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.4\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6005d64",
   "metadata": {},
   "source": [
    "# 1-11 load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d3b56ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f7b41cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    178\n",
       "1    182\n",
       "2    177\n",
       "3    183\n",
       "4    181\n",
       "5    182\n",
       "6    181\n",
       "7    179\n",
       "8    174\n",
       "9    180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(digits.data)\n",
    "print(digits.data.shape)\n",
    "digits_data = digits.data  # data\n",
    "digitsdf = pd.DataFrame(data=digits.target)\n",
    "digitsdf.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "bb38f45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(digits.target)\n",
    "print(digits.target.shape)\n",
    "print(digits.target_names)\n",
    "print(digits.images.shape)\n",
    "\n",
    "digits_label = digits.target # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "47f27e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
    "                                                    digits_label,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=67,\n",
    "                                                   stratify = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efcd73",
   "metadata": {},
   "source": [
    "## 1-11 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "88e5501c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70,  0,  0,  0,  1,  0,  1,  0,  0,  0],\n",
       "       [ 1, 65,  5,  1,  2,  0,  1,  1,  5,  1],\n",
       "       [ 0,  1, 61,  0,  0,  1,  3,  1,  4,  0],\n",
       "       [ 0,  0,  1, 51,  1,  1,  1,  0,  4,  6],\n",
       "       [ 0,  8,  0,  1, 62,  0,  1,  3,  0,  2],\n",
       "       [ 0,  0,  1,  3,  1, 64,  2,  2,  2,  0],\n",
       "       [ 0,  0,  1,  0,  0,  1, 76,  0,  1,  0],\n",
       "       [ 0,  0,  0,  1,  2,  1,  1, 50,  0,  1],\n",
       "       [ 0,  3,  2,  5,  1,  3,  1,  1, 41,  2],\n",
       "       [ 4,  2,  2,  4,  1,  1,  0,  2,  4, 63]], dtype=int64)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "decision_digit = DecisionTreeClassifier(random_state=42)\n",
    "decision_digit.fit(X_train, y_train)\n",
    "y_pred = decision_digit.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0a5d2d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        72\n",
      "           1       0.82      0.79      0.81        82\n",
      "           2       0.84      0.86      0.85        71\n",
      "           3       0.77      0.78      0.78        65\n",
      "           4       0.87      0.81      0.84        77\n",
      "           5       0.89      0.85      0.87        75\n",
      "           6       0.87      0.96      0.92        79\n",
      "           7       0.83      0.89      0.86        56\n",
      "           8       0.67      0.69      0.68        59\n",
      "           9       0.84      0.76      0.80        83\n",
      "\n",
      "    accuracy                           0.84       719\n",
      "   macro avg       0.83      0.84      0.84       719\n",
      "weighted avg       0.84      0.84      0.84       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1cd4a3",
   "metadata": {},
   "source": [
    "## 1-11 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "72629dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6c9f5510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        72\n",
      "           1       0.98      1.00      0.99        82\n",
      "           2       0.99      1.00      0.99        71\n",
      "           3       1.00      0.94      0.97        65\n",
      "           4       0.97      0.96      0.97        77\n",
      "           5       0.95      0.93      0.94        75\n",
      "           6       0.97      0.99      0.98        79\n",
      "           7       0.90      0.98      0.94        56\n",
      "           8       0.90      0.92      0.91        59\n",
      "           9       0.97      0.92      0.94        83\n",
      "\n",
      "    accuracy                           0.96       719\n",
      "   macro avg       0.96      0.96      0.96       719\n",
      "weighted avg       0.96      0.96      0.96       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1572c24a",
   "metadata": {},
   "source": [
    "## 1-11 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "594c9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e94770d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        72\n",
      "           1       1.00      1.00      1.00        82\n",
      "           2       1.00      1.00      1.00        71\n",
      "           3       1.00      0.98      0.99        65\n",
      "           4       1.00      0.96      0.98        77\n",
      "           5       0.99      0.97      0.98        75\n",
      "           6       0.99      1.00      0.99        79\n",
      "           7       0.98      1.00      0.99        56\n",
      "           8       0.92      0.98      0.95        59\n",
      "           9       0.98      0.96      0.97        83\n",
      "\n",
      "    accuracy                           0.99       719\n",
      "   macro avg       0.99      0.99      0.99       719\n",
      "weighted avg       0.99      0.99      0.99       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9ef4c",
   "metadata": {},
   "source": [
    "## 1-11 SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4b7c2d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 81,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0, 71,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 58,  0,  2,  0,  1,  2,  2],\n",
       "       [ 0,  1,  0,  0, 74,  0,  0,  0,  1,  1],\n",
       "       [ 0,  1,  0,  0,  0, 70,  1,  0,  1,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0, 79,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 54,  0,  2],\n",
       "       [ 0,  2,  1,  1,  0,  2,  0,  0, 52,  1],\n",
       "       [ 0,  2,  0,  0,  0,  0,  0,  0,  0, 81]], dtype=int64)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ed46bd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        72\n",
      "           1       0.93      0.99      0.96        82\n",
      "           2       0.99      1.00      0.99        71\n",
      "           3       0.98      0.89      0.94        65\n",
      "           4       1.00      0.96      0.98        77\n",
      "           5       0.95      0.93      0.94        75\n",
      "           6       0.99      1.00      0.99        79\n",
      "           7       0.98      0.96      0.97        56\n",
      "           8       0.91      0.88      0.90        59\n",
      "           9       0.91      0.98      0.94        83\n",
      "\n",
      "    accuracy                           0.96       719\n",
      "   macro avg       0.96      0.96      0.96       719\n",
      "weighted avg       0.96      0.96      0.96       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b37db6",
   "metadata": {},
   "source": [
    "## 1-11 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7d753449",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "25514eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juwon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ecdf06b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        72\n",
      "           1       0.97      0.95      0.96        82\n",
      "           2       0.97      0.99      0.98        71\n",
      "           3       0.97      0.94      0.95        65\n",
      "           4       1.00      0.96      0.98        77\n",
      "           5       0.95      0.95      0.95        75\n",
      "           6       0.98      1.00      0.99        79\n",
      "           7       1.00      1.00      1.00        56\n",
      "           8       0.82      0.95      0.88        59\n",
      "           9       0.97      0.92      0.94        83\n",
      "\n",
      "    accuracy                           0.96       719\n",
      "   macro avg       0.96      0.96      0.96       719\n",
      "weighted avg       0.97      0.96      0.96       719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002359c6",
   "metadata": {},
   "source": [
    "## 평가\n",
    "* 5가지의 모델로 load_digit를 학습시켰다. 학습의 평가를 위해 classification_report를 사용했다.\n",
    "\n",
    "\n",
    "* max_iter는 warning 문구가 나오지 않을 때 까지 100씩 올렸다.\n",
    "\n",
    "\n",
    "* 평가지표로 precision과 recall, f1-score가 있지만 precision과 recall의 조화평균을 계산한 f1-score를 선택했다.\n",
    "\n",
    "\n",
    "* 조화평균이 산술평균과 다른점은 산술평균의 경우 극단적인 데이터에 영향을 받지만, 조화평균의 경우 두 데이터의 차이가\n",
    "극단적일 경우 0에 수렴한 값을 내기 때문이다.\n",
    "\n",
    "\n",
    "* SVM, RandomForestClassifier, LogisticRegression, SGDClassifier, DecisionTreeClassifier순으로 정확하다고 볼 수 있다.\n",
    "\n",
    "\n",
    "* 상위 세가지 모델의 f1-score는 비슷하지만 SVM의 편차가 가장 적다. 숫자 분류에는 SVM이 적합하다.\n",
    "\n",
    "\n",
    "* SGDClassifier의 경우 f1-score가 모델 특성상 값이 바뀌긴 하지만 평균적으로 0.9이상이 나왔다.\n",
    "\n",
    "\n",
    "* 각 숫자마다 학습한 데이터의 개수가 비슷함에도 불구하고 5개 모델들 전부 5 ,8, 9에 대한 f1-score가 낮게 나왔다.\n",
    "\n",
    "\n",
    "* SGDClassifier에서 8에 대한 precision과 recall의 값의 편차가 컸다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c6039",
   "metadata": {},
   "source": [
    "# 1-12 load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "089733c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "dad768ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59\n",
      "1    71\n",
      "2    48\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  label  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "wine_df['label']=wine.target\n",
    "\n",
    "print(wine_df['label'].value_counts().sort_index())\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2531292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = wine.data\n",
    "wine_label = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5319cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_data,\n",
    "                                                    wine_label,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=67,\n",
    "                                                   stratify = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ec37f",
   "metadata": {},
   "source": [
    "## 1-12 DecisionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "29240591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  0,  0],\n",
       "       [ 1, 21,  2],\n",
       "       [ 0,  1, 12]], dtype=int64)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_wine = DecisionTreeClassifier(random_state=42)\n",
    "decision_wine.fit(X_train, y_train)\n",
    "y_pred = decision_wine.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6dae0c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        17\n",
      "           1       0.95      0.88      0.91        24\n",
      "           2       0.86      0.92      0.89        13\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.92      0.93      0.92        54\n",
      "weighted avg       0.93      0.93      0.93        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f13bba",
   "metadata": {},
   "source": [
    "## 1-12 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e452017b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  0,  0],\n",
       "       [ 0, 24,  0],\n",
       "       [ 0,  0, 13]], dtype=int64)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_wine = RandomForestClassifier(random_state=42)\n",
    "random_forest_wine.fit(X_train, y_train)\n",
    "y_pred = random_forest_wine.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "af111a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       1.00      1.00      1.00        24\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acaeb86",
   "metadata": {},
   "source": [
    "## 1-12 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8b02e16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  0,  0],\n",
       "       [ 0, 21,  3],\n",
       "       [ 0, 10,  3]], dtype=int64)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model_wine = svm.SVC()\n",
    "svm_model_wine.fit(X_train, y_train)\n",
    "y_pred = svm_model_wine.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5ddaa8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       0.68      0.88      0.76        24\n",
      "           2       0.50      0.23      0.32        13\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.73      0.70      0.69        54\n",
      "weighted avg       0.74      0.76      0.73        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ec0f0",
   "metadata": {},
   "source": [
    "## 1-12 SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "da937aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 2 1 1 2 2 1 0 2 0 1 0 0 0 0 2 1 0 1 2 1 1 0 0 0 1 0 2 2 1 1 1 0 1 2\n",
      " 1 1 1 1 2 0 1 1 2 0 1 0 1 1 0 0 2]\n",
      "[1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 0 1]\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[17,  0,  0],\n",
       "       [ 0, 24,  0],\n",
       "       [ 1, 12,  0]], dtype=int64)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model_wine = SGDClassifier()\n",
    "sgd_model_wine.fit(X_train, y_train)\n",
    "y_pred= sgd_model_wine.predict(X_test)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(np.unique(y_pred))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "bf1de78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        17\n",
      "           1       0.67      1.00      0.80        24\n",
      "           2       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.76        54\n",
      "   macro avg       0.54      0.67      0.59        54\n",
      "weighted avg       0.59      0.76      0.66        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juwon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\juwon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\juwon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787d284",
   "metadata": {},
   "source": [
    "## 1-12 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e3f02f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juwon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16,  1,  0],\n",
       "       [ 0, 24,  0],\n",
       "       [ 0,  0, 13]], dtype=int64)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model_wine = LogisticRegression(max_iter=100)\n",
    "logistic_model_wine.fit(X_train, y_train)\n",
    "y_pred = logistic_model_wine.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "92d78e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        17\n",
      "           1       0.96      1.00      0.98        24\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.99      0.98      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623525a",
   "metadata": {},
   "source": [
    "## 평가\n",
    "* load_digit과 같은 모델과 classification_report를 사용했다.\n",
    "\n",
    "\n",
    "* max_iter 역시 같은 방법으로 올렸다.\n",
    "\n",
    "\n",
    "* f1-score를 평가지표로 사용했으며, LogisticRegression, RandomForestClassifier, DecisionTreeClassifier가 유의미한 분류를 했다.\n",
    "\n",
    "\n",
    "* SVM의 경우 digits와 다르게 좋은 결과가 나오지 않았다. 아마도 feature의 값들의 차이가 크기 때문인 것 같다.   \n",
    "Cost 값을 올릴수록 모델의 성능은 더 좋아졌다.\n",
    "\n",
    "* SGDClassifier에서 두 번 돌리면 한 번 꼴로 warning 문구가 나왔다. precision 값이 0이여서 f1-score를 구하지 못했다고 한다.\n",
    "y_pred 값을 보면 전체 라벨이 총 3개인데 2개밖에 없음을 알 수 있다.\n",
    "\n",
    "* Logistic Regression의 max_iter값을 100부터 올려서 3200까지 올려봤지만 오분류 개수는 1개에서 변함 없었다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b1d12",
   "metadata": {},
   "source": [
    "# 1-13 load breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "12560d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6cac1a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "0    212\n",
      "1    357\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancerdf=pd.DataFrame(data = breast_cancer.data,columns = breast_cancer.feature_names)\n",
    "breast_cancerdf['label']=breast_cancer.target\n",
    "print(breast_cancer.target_names)\n",
    "print(breast_cancerdf['label'].value_counts().sort_index())\n",
    "breast_cancerdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ef8ecf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data = breast_cancer.data\n",
    "breast_cancer_label = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "bc202904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data,\n",
    "                                                    breast_cancer_label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704819ad",
   "metadata": {},
   "source": [
    "## 1-13 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1dd9f0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  5],\n",
       "       [ 4, 72]], dtype=int64)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_breast_cancer = DecisionTreeClassifier(random_state=42)\n",
    "decision_breast_cancer.fit(X_train, y_train)\n",
    "y_pred = decision_breast_cancer.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8a7802e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88        38\n",
      "           1       0.94      0.95      0.94        76\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.91      0.91      0.91       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945dc9f6",
   "metadata": {},
   "source": [
    "## 1-13 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1754232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_breast_cancer= RandomForestClassifier(random_state=42)\n",
    "rf_breast_cancer.fit(X_train, y_train)\n",
    "y_pred = rf_breast_cancer.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d3903aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        38\n",
      "           1       0.96      1.00      0.98        76\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.96      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f65d0",
   "metadata": {},
   "source": [
    "## 1-13 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "561e42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_breast_cancer = svm.SVC()\n",
    "svm_breast_cancer.fit(X_train, y_train)\n",
    "y_pred = svm_breast_cancer.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d0a85a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.74      0.84        38\n",
      "           1       0.88      0.99      0.93        76\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.86      0.88       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ca5ca",
   "metadata": {},
   "source": [
    "## 1-13 SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f065a1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34,  4],\n",
       "       [11, 65]], dtype=int64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc_breast_cancer = SGDClassifier()\n",
    "sgdc_breast_cancer.fit(X_train, y_train)\n",
    "y_pred = sgdc_breast_cancer.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b7b8ac2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82        38\n",
      "           1       0.94      0.86      0.90        76\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.85      0.88      0.86       114\n",
      "weighted avg       0.88      0.87      0.87       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad68762",
   "metadata": {},
   "source": [
    "## 1-13 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b0f77236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  5],\n",
       "       [ 1, 75]], dtype=int64)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_breast_cancer= LogisticRegression(max_iter=430)\n",
    "lr_breast_cancer.fit(X_train, y_train)\n",
    "y_pred = lr_breast_cancer.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8008d678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92        38\n",
      "           1       0.94      0.99      0.96        76\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb8011",
   "metadata": {},
   "source": [
    "## 평가\n",
    "* load_digit과 같은 모델과 classification_report를 사용했다.\n",
    "\n",
    "\n",
    "* max_iter 역시 같은 방법으로 올렸다.\n",
    "\n",
    "\n",
    "* load_breast_cancer의 타겟은 0,1로 악성과 양성을 나타낸다. 악성을 양성으로 진단하는 것은 매우 치명적이기 때문에\n",
    "악성(y_test = 0)에 대한 recall 값을 평가지표로 사용했다.\n",
    "\n",
    "* RandomForestClassifier, LogisticRegression, DecisionTreeClassifier 순으로 높았으며, SVM은 recall값이 낮고, SGDClassifier는 값의\n",
    "편차가 커서 적합하지 않다고 판단했다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde9329",
   "metadata": {},
   "source": [
    "# 마치며\n",
    "\n",
    "* DecisionTreeClassifier는 전반적으로 나쁘지 않은 결과를 보여주었다. 그래서 애매한 모델이라고 생각이 들었다.\n",
    "하지만 디폴트로 진행했다는 점, feature 값들이 많아서(?) 과적합에 빠졌다고 생각이 들었다. 적당한 튜닝이 들어간다면 \n",
    "우수한 결과를 기대할 수 있다고 생각한다.   \n",
    "\n",
    "\n",
    "* RandomForestClassifier는 3개의 데이터에서 우수한 성능을 보였다. ensemble method를 통해 과적합을 방지하고 많은 feature들을\n",
    "다룰 수 있다. DecisionTreeClassifier의 단점을 극복한 개념이기에 당연히 모든 데이터에서 DecisionTreeClassifier 보다 우수한 \n",
    "학습률을 보였다.   \n",
    "\n",
    "\n",
    "* SVM은 digits의 성능에서 매우 우수하게 분류 했지만, 다른 데이터에선 그러지 못했다. 그래서 다른 데이터들의 Cost 값(default=1)을 \n",
    "10배씩 10000까지 올려주었는데 accuracy가 0.95까지 올라갔었다. 이유를 생각해본다면 Cost를 올려주면 결정경계가 선형에서 비선형으로\n",
    "바뀌는데 이를 통해 여러 차원에 존재하는 값들을 잘 분리할 수 있었던 거 같다.   \n",
    "\n",
    "\n",
    "* SGDClassifier는 fit 할 때마다 편차가 컸는데 SGDClassifier는 전체 데이터들 중 무작위 학습으로 경사를 줄여나가는데,\n",
    "digits에 비해 두 데이터는 데이터의 양이 적기 때문에 편차가 크게 나타난다고 생각한다. wine에서 y_pred 값을 보면 3개의 라벨 중 \n",
    "2개 밖에 학습을 하지 못한 것을 알 수 있다. 데이터가 적을 땐 다른 모델을 쓰거나 튜닝이 필요할 것 같다고 생각했다.   \n",
    "\n",
    "\n",
    "* LogisticRegression은 전반적으로 우수한 성능을 보였다. LogisticRegression은 이진분류에선 sigmoid 다중 분류에서 softmax함수를 사용한다. softmax를 통해 높은 확률을 가진 데이터를 클래스에 넣는데, softmax에서의 단점인 단조증가에 의해서 feature값들을 정규화 해주지 않는다면 성능이 떨어질 것이다. 이진분류에서 강한 LogisticRegression이 load_breast에서 RandomForestClassifier보다 정확도가 떨어진 이유일 듯 싶다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea932794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
